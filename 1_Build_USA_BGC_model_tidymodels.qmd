---
title: "Build ranger model of USA BGC"
format: html
editor: visual
author: "William H MacKenzie & Kiri Daust"
date: "20/04/2024"
---

### Script to create RF model from USA training points and predict + map US zones/ subzones (predicted within each zone)

1.  Import training data
2.  Reduce variable list with caret or PCA all variable
3.  Test machine learning model with analysis/assessment splits and CV
4.  Report errors rate
5.  Build final model
6.  Predict Translates predictions to a grid point map Add predictions to hex polygon layer. Overlay additional plots over map to assign to USA_BGC units

# STEP 1: Prepare dataset for analysis----clear workspace

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
require(reshape)
require(reshape2)
require(parallel)
require(foreach)
require(doParallel)
require(ggplot2)
require(dplyr)
require(ranger)
require (tools)
require(data.table)
require(spatstat)
#require(spatialEco)
require(survey)
require(scales)
require(tidyverse)
require(rlang)
require(Rcpp)
require(forcats)
require(purrrlyr)
require(skimr)
require(smotefamily)
require(tictoc)
require(tidymodels)
require(spatialsample)
require(themis)
#require(conflicted)
require(ggtext)
tidymodels_prefer()
#install.packages ("spThin")
conflicted::conflict_prefer(name = "spec", winner = "yardstick")

source("./_functions/AddVars.R")
source("./_functions/removeOutlier.R")
source("./_functions/acc_metrix.R")
```

# Import USA training point data

CSV file with all variable climate data generated by ClimateNA for the 1960-91 Normal Period. \*\*\* Need to update data to climateNA7

Several additional climate variables are calculated

```{r input data, echo=FALSE}
X1 <- readRDS("./inputs/training_pts/USA_training_data_15Apr2024.rds")
X1 <- addVars(X1)

vars.selected <- fread("no_month_vars.csv")
vars.selected <- vars.selected$vars
X2 <- X1 %>% dplyr::select(id, BGC, vars.selected)
X1 <- X2

```

# remove undersampled BGCs

```{r remove undersampled}
##count of BGC points
num_pts <- X1 %>% group_by(BGC) %>% count()
bad_BGCs <- num_pts %>% filter(n<20) %>% select(BGC)
fwrite(num_pts, "./outputs/TrainingPointCount.csv")

removeBGCs <- c("duplicate", "Duplicate", "na")
X1 <- X1 %>% dplyr::filter(!(BGC %in% bad_BGCs$BGC))# %>% filter(Latitude >= 41)

# merge parkland into adjacent alpine unit
X1$BGC <- X1$BGC %>% recode( MHdsp_OR = "CMAun_OR", MHRFdmp_OR = "CMAun_OR", MHRFmmp_OR = "CMAun_OR", MHmsp_WA = "CMAun_WA",
                             "MHRFdsp_CA" = "CMAun_CA", "MHdsp_OR" = "CMAun_OR" , "MHRFdmp_OR"= "CMAun_OR" , "MHRFmmp_OR"= "CMAun_OR" , 
                            "MHmsp_WA" ="CMAun_WA" , "MHmmp_WA"= "CMAun_WA" ,"MHdmp_OR"= "CMAun_OR",
                             "ESSFxcp_CO"=  "IMAun_CO" , "ESSFwmp_MT"="IMAun_MT" , "ESSFxkp_UT"= "IMAun_UT" , "ESSFxkp_MT"= "IMAun_MT" , 
                             "ESSFdmp_ID"="IMAun_ID" ,"ESSFdkp_MT"=  "IMAun_MT" ,"ESSFxcp_WA" = "IMAun_WA" ,"ESSFmwp_WA" = "IMAun_WA" ,
                           "ESSFxwp_OR" = "IMAun_OR", "ESSFxxp_WY" = "IMAun_WY", "ESSFxkp_WY" = "IMAun_WY")

### count training points per BGC
count_tp <- X1 %>% dplyr::count(BGC) %>% filter(n<=10) %>% select(BGC)
count_tp <-  as.character(count_tp$BGC)
X1 <- X1 %>% filter(!BGC %in% count_tp)

## merge of related units with high confusion in first run
#X1$BGC <- X1$BGC %>% recode( CDFmm_WA = "CDFmm")# , MHRFdmp_OR = "CMAun_OR")
#                             , MHRFmmp_OR = "CMAun_OR", MHmsp_WA = "CMAun_WA",
#                              "MHRFdsp_CA" = "CMAun_CA", "MHdsp_OR" = "CMAun_OR" , "MHRFdmp_OR"= "CMAun_OR" , "MHRFmmp_OR"= "CMAun_OR" , 
#                             "MHmsp_WA" ="CMAun_WA" , "MHmmp_WA"= "CMAun_WA" ,
#                              "ESSFxcp_CO"=  "IMAun_CO" , "ESSFwmp_MT"="IMAun_MT" , "ESSFxkp_UT"= "IMAun_UT" , "ESSFxkp_MT"= "IMAun_MT" , 
#                              "ESSFdmp_ID"="IMAun_ID" ,"ESSFdkp_MT"=  "IMAun_MT" ,"ESSFxcp_WA" = "IMAun_WA" ,"ESSFmwp_WA" = "IMAun_WA" ,
#                            "ESSFxwp_OR" = "IMAun_OR" )
X1 <- X1 %>% mutate(across(where(is.numeric), ~na_if(.,-9999.0))) %>% drop_na()

 count_tp <- X1 %>% dplyr::count(BGC)

 BGCs <- sort(unique(X1$BGC))
BGCs
#X1 <- X2
```

##Remove outliers points Looks for training points which fall climatically well outside of the normal range by BGC. Mostly aimed at catching the 10% of FIA plots which have been given an intentionally large offset georeferenced location May also indicate overly broad BGCs (eg. IMAus)

```{r remove outlier points}


 X2 <- removeOutlier(X1, alpha = .025, numIDvars = 2) %>% droplevels###set alpha for removal of outlieres (2.5% = 3SD)
 count_tp <- X2 %>% dplyr::count(BGC)

```

### Remove points to ensure a spacing of at least 1km between training points

```{r thin data to limit spatial autocorrelation}

rad_exclusion = 1000 ##  minimum meters between points


```

### Raw training point distribution bar graph

```{r raw training point summary, echo = FALSE, include = TRUE}
# calculate summary of raw training data set
X2_sum <- X2 %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot(X2_sum, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))

X2$BGC <- as.factor(X2$BGC)
X2 <- X2 %>% dplyr::rename(ID = id)
BGC_split <- initial_split(X2, prop = 3/4, strata = BGC)
BGC_train <- training(BGC_split)
BGC_test <- testing(BGC_split)

BGCbalance_recipe <-  recipe(BGC ~ ., data =  BGC_test) %>%
  #step_downsample(BGC, under_ratio = 50) %>%   
  #step_smote(BGC, over_ratio = .5, neighbors = 10) %>% 
    prep()
BGC_test2 <- BGCbalance_recipe  %>% juice()
  BGC_test_sum <- BGC_test2 %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot(BGC_test_sum, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
    ggtitle("Training Set")

```

### Downsampled training point distribution bar graph

```{r tidy parameters, include = TRUE, echo = TRUE}

BGC_recipe <-
    recipe(BGC ~ ., data = BGC_train) %>%

    update_role(ID, new_role = "id variable") %>% 
    #update_role(lat, long, new_role = "georef") %>% 
    #step_corr(all_numeric(0.9)) %>%        # remove correlated covariates
    #step_dummy(all_nominal(),-all_outcomes()) %>%   
    #step_zv(all_numeric()) %>%          # remove values with no variance
    prep()
  summary(BGC_recipe)
  
# pre-processed training point data check 

#table(training_dat$target)
  BGC_train_sum <- BGC_train %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot( BGC_train_sum, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
    ggtitle("Training Set")
    
## note in RF as a tree based model it is not required to scale and normalize covariates and may have negative influence on the model performance 

BGCbalance_recipe <-  recipe(BGC ~ ., data =  BGC_train) %>%
    update_role(ID, new_role = "id variable") %>% 
    #update_role(lat, long, new_role = "georef") %>% 
    #step_corr(all_numeric()) %>%        # remove correlated covariates
    #step_dummy(all_nominal(),-all_outcomes()) %>%    
    # step_zv(all_numeric()) %>% # remove values with no variance
  #step_downsample(BGC, under_ratio = 20) %>%  
  step_nearmiss(BGC, under_ratio = 33) %>%  
  #step_smote(BGC, over_ratio = .33, neighbors = 10) %>% 
    prep()
BGC_train2 <- BGCbalance_recipe  %>% juice()
BGC_train2$BGC <- as.factor(BGC_train2$BGC)
  
  BGC_train_sum2 <- BGC_train2 %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot( BGC_train_sum2, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
  ggtitle("Up/downsampled set")
 count_tp2 <- BGC_train2 %>% dplyr::count(BGC)
```

### Quick model generation and test set accuracy

```{r fit non-cv model  comparison, error=TRUE}
randf_spec <- rand_forest(mtry = 6, min_n = 2, trees = 101) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = 'permutation') #or "permutations"impurity"
BGCbalance_recipe <-  recipe(BGC ~ ., data =  BGC_train) %>%
    update_role(ID, new_role = "id variable") %>% 
    step_nearmiss(BGC, under_ratio = 33)

BGC_workflow <- workflow() %>%
    add_recipe(BGCbalance_recipe) %>%
    add_model(randf_spec)

BGC_rf1 <- fit(
  BGC_workflow, 
  BGC_train)

######### Predict Test
test_target <- as.data.frame(BGC_test2$BGC) %>% rename(BGC = 1)
test.pred <-  predict(BGC_rf1, BGC_test2)
test.pred <- cbind(test_target, test.pred) %>% mutate_if(is.character, as.factor)
# levels(train.pred$target)

###harmonize levels
targ.lev <- levels(test.pred$BGC); pred.lev <- levels(test.pred$.pred_class)
levs <- c(targ.lev, pred.lev) %>% unique()
test.pred$BGC <- factor(test.pred$BGC, levels = levs)
test.pred$.pred_class <- factor(test.pred$.pred_class, levels = levs)
# 
# 
# train.acc <- acc_metrix(train.pred) %>% rename(train = .estimate)
source("./_functions/acc_metrix.R")
test.acc <- acc_metrix(test.pred) %>% dplyr::select(.metric, .estimate) %>% rename(metric = 1, test = 2)

test.out <-   test.pred %>% 
   conf_mat(BGC, .pred_class) %>%
   pluck(1) %>%
   as_tibble()
```

### Deviation graphing show ing over and underpredicted BGCs

```{r create deviation graphic}
# calculate predicted vs obs pc for balancing types 
# negative number = under predict and positive = over predicted)

BGC.truth <- test.pred %>%
  count(BGC) %>% rename("truth" = n)
BGC.pred <- test.pred %>%
  count(.pred_class) %>% rename("predict" = n, "BGC" = .pred_class)
BGC_dev <- left_join(BGC.truth, BGC.pred) %>% group_by(BGC)
BGC_dev <- BGC_dev %>% 

  mutate(pred.diff = predict - truth,
         pred_pc = (pred.diff/truth) * 100) %>% arrange(pred_pc)

df_total <- as.data.frame(BGC_dev) %>% replace(is.na(.), 0)

df_total2 <- df_total  %>%  group_by() %>% 
            summarise(dev_tot = sum(abs(pred_pc)),
            dev_var = var(abs(pred_pc)),
            dev_mean = mean(abs(pred_pc)),
            dev_sd = sd(abs(pred_pc))) 


devtext <- as.data.frame(t(df_total2)) %>% round(1) %>% rownames_to_column()


BGC_dev  <- BGC_dev  %>%
  mutate(BGC = fct_reorder(BGC, pred_pc))

  ds_plot <- BGC_dev %>%   ggplot( aes(x=reorder(BGC, pred_pc), y=pred_pc)) +
    geom_bar(stat='identity', width=.5) + #aes(fill = pred.obs.type)
    coord_flip(ylim =c(-100, 110))
label = df_total2 [3] %>% round(1)
# ds_plot <- ds_plot +
#   geom_textbox(data = devtext, width = .1,
#             size = 3, 
#             mapping = aes(x = 20 , y = -60 ,label = label),
#             colour = "blue"
#   )

ds_plot
require(ggpubr)
ggexport(ds_plot, filename  = "./outputs/Deviation_graph.jpg", pointsize = 6, width = 800, height = 1200)

```

### Build and save a final model for predicting state maps

```{r build final tidy model}
require(themis)
BGC_final <- X2# %>% rename(ID = id)


randf_spec <- rand_forest(mtry = 6, min_n = 2, trees = 201) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "permutation") #or "permutations


BGC_recipe <-  recipe(BGC ~ ., data =  BGC_final) %>%
    update_role(ID, new_role = "id variable")%>% 
  step_nearmiss(BGC, under_ratio = 33)# %>%   
  #step_smote(BGC, over_ratio = .33, neighbors = 5) %>%
# prep()

BGC_workflow <- workflow() %>%
    add_recipe(BGC_recipe) %>%
    add_model(randf_spec)
### Show number of final training points
BGC_all <- BGC_recipe  %>% prep() %>% juice()
BGC_all$BGC <- as.factor(BGC_all$BGC)
  BGC_all <- BGC_all %>%
  dplyr::group_by(BGC) %>%
  dplyr::summarise(freq = n()) %>%
  dplyr::mutate(prop = round(freq/sum(freq),3))

ggplot( BGC_all, aes(x= reorder(BGC, -prop), y = freq)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90))+
  ggtitle("Up/downsampled set")

BGCmodel <- fit(
  BGC_workflow, 
  BGC_final)

save(BGCmodel,file= "./outputs/USAv13_19Apr2024tidymodel.Rdata")
#load("./outputs/USAv12_tidymodel.Rdata")

##report model
#   require(vip)
# final_fit <- extract_fit_parsnip(BGCmodel) # %>%pull(.predictions)
# final_fit
# oob  <- round(BGCmodel$fit$fit$fit$prediction.error, 3)
# extract_fit_parsnip(BGCmodel) %>% vip(num_features = 26)

```
